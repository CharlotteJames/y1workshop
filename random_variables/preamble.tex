This worksheet builds on the earlier worksheet on probability, introducing the idea of random variables, mean and variance and some common probability distributions.\\

\subsubsection*{Random variables}

Let $S$ be the sample space for a random trial. Now define a function $\phi: S\to \mathbb{R}$. Then $\phi$ acting on $S$ defines a random variable, written $X$.\\
\newline
{\bf Example}\\
Consider the random trial of tossing a fair coin twice. Then $S = \left\{HH, HT, TH, TT \right\}$. We could define our random variable $X$ to be the number of heads obtained, and so we would have $\phi(HH)=2$, $\phi(HT)=1$, $\phi(TH)=1$ and $\phi(TT)=0$.

Random variables can either be discrete or continuous.
\begin{itemize}
 \item {\em Discrete} random variables are defined on the sample space of a random trial with a set of discrete outcomes (e.g. throwing a die or tossing a coin).
 \item {\em Continuous} random variables are defined on the sample space of a random trial where the outcome can take any value from a range (e.g. the heights of people).
\end{itemize}

Some of the key concepts for discrete and continuous random variables are given in the table below.\\

\begin{center}
    \begin{tabular}{|p{7cm} | p{7cm}|}
    \hline
    {\bf Discrete} & {\bf Continuous} \\ \hline
    Probability function:  & Probability density function (pdf):  \\
    $P_{X}(x):=P(X=x)$ & $P(x_{1}\leq x \leq x_{2})=\int_{x_{1}}^{x_{2}}f_{X}(x)\:\mathrm{d}x$ \\ \hline
    Cumulative distribution function (cdf): & Cumulative distribution function (cdf): \\
    $F_{X}(x):=P(X\leq x)=\sum_{\tilde{x} \leq x} P_{X}(\tilde{x})$ & $F_{X}(x):=P(X\leq x)=\int_{-\infty}^{x}f_{X}(\tilde{x})\mathrm{d}\tilde{x}$ \\ \hline
    Expected value (mean): & Expected value (mean): \\ 
    $\mu=E(X):=\sum_{x} x P_{X}(x)$ & $\mu=E(X)=\int_{-\infty}^{\infty}x f_{X}(x)\: \mathrm{d}x$ \\
    \hline
    \end{tabular}
\end{center}

The {\em variance} of any random variable is defined in terms of the expected value as
\begin{equation*}
\text{Var}(X)=\sigma^{2}:=E((X-\mu)^{2})=E(X^{2})-\mu^{2}.
\end{equation*}
This looks like a lot of maths! Let's look at a simple example to try to understand what is going on.\\
\newline
{\bf Example}\\
Consider the random trial of tossing a fair coin three times in succession. Suppose we are just interested in how many times we get tails. Therefore we define our random variable $X$ to be the number of tails. So we have $\phi(HHH)=0$, $\phi(HHT)=1$ etc. as in our earlier example. The number of tails $X$ can either be 0, 1, 2 or 3. The probability function just gives the probability of our random variable $X$ taking the value $x$. For instance $P_{X}(0)=\frac{1}{8}$. The probability function is shown in the table below. 

\begin{center}
\begin{tabular}{ |c|c|c|c|c| } 
 \hline
 $x$ & 0 & 1 & 2 & 3 \\ 
\hline $P_{X} (x)$& $\frac{1}{8}$ & $\frac{3}{8}$ & $\frac{3}{8}$ & $\frac{1}{8}$ \\
 \hline
\end{tabular}
\end{center}

The cdf gives us the probability that our random variable $X$ takes a value less than or equal to x. For instance
\begin{equation*}
F_{X}(2)=P(X\leq 2)=\sum_{\tilde{x} \leq 2} P_{X}(\tilde{x})=P_{X}(0)+P_{X}(1)+P_X(2)=\frac{1}{8}+\frac{3}{8}+\frac{3}{8}=\frac{7}{8}.
\end{equation*}
This is just saying that there is a $\frac{7}{8}$ probability for the number of tails $X\leq 2$. The full cdf is given in the table below.

\begin{center}
\begin{tabular}{ |c|c|c|c|c| } 
 \hline
 $x$ & 0 & 1 & 2 & 3 \\ 
\hline $F_{X} ( x)$& $\frac{1}{8}$ & $\frac{4}{8}$ & $\frac{7}{8}$ & $1$ \\
 \hline
\end{tabular}
\end{center}

The expected value $E(X)$ can be found by summing up $x P_{X}(x)$ for all values our random variable can take. So for our example:
\begin{equation*}
 \mu=E(X)=\sum_{x} x P_{X}(x)=0 \frac{1}{8}+1 \frac{3}{8} + 2 \frac{3}{8} + 3\frac{1}{8}=1.5.
\end{equation*}
This tells us that we would expect to get 1.5 heads when tossing a fair coin three times.

\subsubsection*{Distributions}
Depending on what you trying to model, there are a number of common distributions that can capture what is going on. A summary of the distributions you have covered so far and their probability functions/pdfs is given below.

\begin{center}
    \begin{tabular}{|p{2.5cm} | p{2.5cm}| p{4cm} | p{5cm}|}
    \hline
    {\bf Distribution} & {\bf Type} & {\bf Parameters} & {\bf Probability function/pdf} \\ \hline
    Bernoulli & Discrete & Prob. success $p$ & $P(0)=1-p$, $P(1)=p$ \\ \hline
    Geometric & Discrete & Prob. success $p$ & $P(k)=p(1-p)^{k-1}$ \\ \hline
    Binomial & Discrete & Prob. success $p$, no. of trials $n$ & $P(k)=\binom{n}{k} p^{k} (1-p)^{n-k}$ \\ \hline
    Poisson & Discrete & Rate $\lambda$ & $P(k)=\frac{\lambda^{k}}{k!}\exp(-\lambda)$ \\ \hline
    Exponential & Continuous & $\lambda$ & $f_{X}(x)=\lambda\exp (-\lambda x)$ if $x\geq 0$, else 0 \\ \hline
    Normal & Continuous & $\mu$, $\sigma$ & $f_{X}(x)=\frac{1}{\sqrt{2 \pi} \sigma}\exp \left( - \frac{(x-\mu)^{2}}{2 \sigma^{2}} \right)$ \\
    \hline
    \end{tabular}
\end{center}

Now for some questions...\\
